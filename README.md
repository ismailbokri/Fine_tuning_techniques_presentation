# Fine_tuning_techniques_presentation
These presentations were created during a summer internship with the company Business &amp; AI. The purpose of these two presentations is to choose the best technique for fine-tuning a large language model (LLM), familiarize with the basic concepts of fine-tuning, and understand the types of data required for the process.
This presentation delves into the basics and the fundamental techniques: PEFT, LoRA, QLoRA, Hypernetworks, Adapter Tuning, Knowledge Distillation, and Prompt Tuning. Each technique will be explained with its principles, benefits, and how it works.
